{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Training dataset shape: (140, 4)\n",
      "Test dataset shape: (74, 4)\n",
      "\n",
      "Training label distribution:\n",
      "label\n",
      "NOCUOUS        73\n",
      "INNOCUOUS      66\n",
      "Detected as     1\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "NOCUOUS        0.521429\n",
      "INNOCUOUS      0.471429\n",
      "Detected as    0.007143\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Training set size: 140\n",
      "Testing set size: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2393: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BERT model...\n",
      "======== Epoch 1 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.68\n",
      "Running Validation...\n",
      "  Accuracy: 0.6081\n",
      "======== Epoch 2 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.64\n",
      "Running Validation...\n",
      "  Accuracy: 0.5946\n",
      "======== Epoch 3 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.57\n",
      "Running Validation...\n",
      "  Accuracy: 0.6351\n",
      "======== Epoch 4 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.48\n",
      "Running Validation...\n",
      "  Accuracy: 0.6081\n",
      "======== Epoch 5 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.39\n",
      "Running Validation...\n",
      "  Accuracy: 0.6216\n",
      "======== Epoch 6 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.31\n",
      "Running Validation...\n",
      "  Accuracy: 0.5946\n",
      "======== Epoch 7 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.20\n",
      "Running Validation...\n",
      "  Accuracy: 0.6216\n",
      "======== Epoch 8 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.12\n",
      "Running Validation...\n",
      "  Accuracy: 0.6216\n",
      "======== Epoch 9 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.07\n",
      "Running Validation...\n",
      "  Accuracy: 0.6216\n",
      "======== Epoch 10 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.06\n",
      "Running Validation...\n",
      "  Accuracy: 0.6351\n",
      "======== Epoch 11 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.05\n",
      "Running Validation...\n",
      "  Accuracy: 0.6081\n",
      "======== Epoch 12 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.05\n",
      "Running Validation...\n",
      "  Accuracy: 0.6351\n",
      "======== Epoch 13 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.03\n",
      "Running Validation...\n",
      "  Accuracy: 0.6351\n",
      "======== Epoch 14 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.03\n",
      "Running Validation...\n",
      "  Accuracy: 0.6216\n",
      "======== Epoch 15 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.03\n",
      "Running Validation...\n",
      "  Accuracy: 0.6216\n",
      "======== Epoch 16 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.02\n",
      "Running Validation...\n",
      "  Accuracy: 0.6216\n",
      "======== Epoch 17 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.02\n",
      "Running Validation...\n",
      "  Accuracy: 0.6351\n",
      "======== Epoch 18 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.02\n",
      "Running Validation...\n",
      "  Accuracy: 0.6216\n",
      "======== Epoch 19 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.02\n",
      "Running Validation...\n",
      "  Accuracy: 0.6351\n",
      "======== Epoch 20 / 20 ========\n",
      "Training...\n",
      "  Average training loss: 0.01\n",
      "Running Validation...\n",
      "  Accuracy: 0.6351\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "Accuracy: 0.6351351351351351\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   INNOCUOUS       0.60      0.55      0.57        33\n",
      "     NOCUOUS       0.66      0.71      0.68        41\n",
      "\n",
      "    accuracy                           0.64        74\n",
      "   macro avg       0.63      0.63      0.63        74\n",
      "weighted avg       0.63      0.64      0.63        74\n",
      "\n",
      "Model, tokenizer, and label dictionary saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import pickle\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import pickle\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed_val = 42\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the training and test datasets\n",
    "train_data = pd.read_csv('/Users/devshah/Documents/WorkSpace/University/year 3/CSC493/emphatic-AI-Winter2025/ambiguity_model/cleaned_dataset.csv')\n",
    "test_data = pd.read_csv('/Users/devshah/Documents/WorkSpace/University/year 3/CSC493/emphatic-AI-Winter2025/ambiguity_model/cleaned_dataset_test.csv')\n",
    "\n",
    "# Remove any rows with NaN values\n",
    "train_data = train_data.dropna(subset=['sentence', 'label'])\n",
    "test_data = test_data.dropna(subset=['sentence', 'label'])\n",
    "\n",
    "# Basic data exploration\n",
    "print(\"Training dataset shape:\", train_data.shape)\n",
    "print(\"Test dataset shape:\", test_data.shape)\n",
    "\n",
    "# Check the distribution of labels\n",
    "print(\"\\nTraining label distribution:\")\n",
    "print(train_data['label'].value_counts())\n",
    "print(train_data['label'].value_counts(normalize=True))\n",
    "\n",
    "# Map labels to integers\n",
    "label_dict = {'INNOCUOUS': 0, 'NOCUOUS': 1}\n",
    "train_data['label_id'] = train_data['label'].map(label_dict)\n",
    "test_data['label_id'] = test_data['label'].map(label_dict)\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X_train = train_data['sentence'].values\n",
    "y_train = train_data['label_id'].values\n",
    "X_test = test_data['sentence'].values\n",
    "y_test = test_data['label_id'].values\n",
    "\n",
    "print(\"\\nTraining set size:\", len(X_train))\n",
    "print(\"Testing set size:\", len(X_test))\n",
    "\n",
    "# Rest of your code remains the same, starting from:\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Your existing encode_sentences function and the rest of the code...\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Tokenize and encode sequences\n",
    "def encode_sentences(texts, tokenizer, max_length=128):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    for text in texts:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "    \n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    \n",
    "    return input_ids, attention_masks\n",
    "\n",
    "# Encode training and testing sets\n",
    "train_input_ids, train_attention_masks = encode_sentences(X_train, tokenizer)\n",
    "test_input_ids, test_attention_masks = encode_sentences(X_test, tokenizer)\n",
    "\n",
    "# Convert targets to tensors - no need to modify the shape here\n",
    "train_labels = torch.tensor(y_train, dtype=torch.long)\n",
    "test_labels = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler=RandomSampler(train_dataset),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    sampler=SequentialSampler(test_dataset),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Modified training function\n",
    "def train_model(model, dataloader, optimizer, scheduler, device):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for step, batch in enumerate(dataloader):\n",
    "        if step % 40 == 0 and step != 0:\n",
    "            print(f'  Batch {step}  of  {len(dataloader)}')\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_attention_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Forward pass - removing token_type_ids parameter\n",
    "        outputs = model(\n",
    "            input_ids=b_input_ids,\n",
    "            attention_mask=b_attention_mask,\n",
    "            labels=b_labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Clip the norm of the gradients to 1.0\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "# Modified evaluation function\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_attention_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Forward pass - removing token_type_ids parameter\n",
    "            outputs = model(\n",
    "                input_ids=b_input_ids,\n",
    "                attention_mask=b_attention_mask\n",
    "            )\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        predictions.extend(np.argmax(logits, axis=1).flatten())\n",
    "        true_labels.extend(label_ids.flatten())\n",
    "    \n",
    "    return predictions, true_labels\n",
    "\n",
    "# Load pre-trained BERT model with correct configuration\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=2,  # Binary classification\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Set up optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "\n",
    "epochs = 20\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training BERT model...\")\n",
    "for epoch in range(epochs):\n",
    "    print(f'======== Epoch {epoch + 1} / {epochs} ========')\n",
    "    print('Training...')\n",
    "    \n",
    "    avg_train_loss = train_model(model, train_dataloader, optimizer, scheduler, device)\n",
    "    print(f\"  Average training loss: {avg_train_loss:.2f}\")\n",
    "    \n",
    "    print(\"Running Validation...\")\n",
    "    predictions, true_labels = evaluate_model(model, test_dataloader, device)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Final evaluation\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "predictions, true_labels = evaluate_model(model, test_dataloader, device)\n",
    "\n",
    "# Convert numeric predictions back to text labels\n",
    "label_map = {v: k for k, v in label_dict.items()}\n",
    "pred_labels = [label_map[pred] for pred in predictions]\n",
    "true_labels_text = [label_map[label] for label in true_labels]\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\nAccuracy:\", accuracy_score(true_labels, predictions))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels_text, pred_labels))\n",
    "\n",
    "\n",
    "print(\"Model, tokenizer, and label dictionary saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
