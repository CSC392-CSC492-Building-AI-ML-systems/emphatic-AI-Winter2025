{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns: ['Unnamed: 0', 'ID', 'Sentence', 'Detected as']\n",
      "\n",
      "Sample data:\n",
      "   Unnamed: 0            ID  \\\n",
      "0           1    library#01   \n",
      "1           2  library#02-1   \n",
      "2           3  library#02-2   \n",
      "3           4    library#03   \n",
      "4           5    library#04   \n",
      "\n",
      "                                            Sentence Detected as  \n",
      "0  All material that is stored in the repository ...     NOCUOUS  \n",
      "1  The Library may want to accept important digit...     NOCUOUS  \n",
      "2  The Library may want to accept important digit...   INNOCUOUS  \n",
      "3  Once material has arrived, <referential>it</re...   INNOCUOUS  \n",
      "4  Allows resources to be reviewed before a decis...   INNOCUOUS  \n",
      "\n",
      "Unique labels: ['NOCUOUS' 'INNOCUOUS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0029430389404296875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 139,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d187dfa2583f4a09b99d3394bfeedc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0024383068084716797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 73,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f11cf2dddf49e5a1f7e177efb452b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/73 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0022530555725097656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 27,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a58257b029d4eeaa6add489a4a28dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0033249855041503906,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429ab17d7e3d4fe4b14a8b1f006467c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6872031092643738, 'eval_accuracy': 0.5616438356164384, 'eval_f1': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.8816, 'eval_samples_per_second': 82.804, 'eval_steps_per_second': 5.671, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003343820571899414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d6d554db2f4cdcac976687f26a389a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6872454881668091, 'eval_accuracy': 0.5616438356164384, 'eval_f1': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.6806, 'eval_samples_per_second': 107.255, 'eval_steps_per_second': 7.346, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0030100345611572266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ecde7875174141ae3709ceb85a45bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6902236342430115, 'eval_accuracy': 0.5205479452054794, 'eval_f1': 0.22222222222222224, 'eval_precision': 0.38461538461538464, 'eval_recall': 0.15625, 'eval_runtime': 0.686, 'eval_samples_per_second': 106.408, 'eval_steps_per_second': 7.288, 'epoch': 3.0}\n",
      "{'train_runtime': 30.0973, 'train_samples_per_second': 13.855, 'train_steps_per_second': 0.897, 'train_loss': 0.697892083062066, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002585887908935547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fddff58cb044779561133b4b6abeb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "{'eval_loss': 0.6902236342430115, 'eval_accuracy': 0.5205479452054794, 'eval_f1': 0.22222222222222224, 'eval_precision': 0.38461538461538464, 'eval_recall': 0.15625, 'eval_runtime': 0.7187, 'eval_samples_per_second': 101.566, 'eval_steps_per_second': 6.957, 'epoch': 3.0}\n",
      "\n",
      "Model saved to ./ambiguity_detection_model\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('train.tsv', sep='\\t')\n",
    "test_df = pd.read_csv('test.tsv', sep='\\t')\n",
    "\n",
    "print(\"Train columns:\", train_df.columns.tolist())\n",
    "print(\"\\nSample data:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nUnique labels:\", train_df[train_df.columns[-1]].unique())\n",
    "\n",
    "label_mapping = {'NOCUOUS': 0, 'INNOCUOUS': 1}  \n",
    "\n",
    "\n",
    "text_column = train_df.columns[0]  \n",
    "label_column = train_df.columns[-1]  \n",
    "\n",
    "train_df[text_column] = train_df[text_column].astype(str)\n",
    "test_df[text_column] = test_df[text_column].astype(str)\n",
    "train_df[label_column] = train_df[label_column].map(label_mapping)\n",
    "test_df[label_column] = test_df[label_column].map(label_mapping)\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples[text_column],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    tokenized['labels'] = examples[label_column]\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "train_tokenized = train_dataset.map(preprocess_function, batched=True, remove_columns=train_dataset.column_names)\n",
    "val_tokenized = val_dataset.map(preprocess_function, batched=True, remove_columns=val_dataset.column_names)\n",
    "\n",
    "\n",
    "train_tokenized.set_format(type=\"torch\")\n",
    "val_tokenized.set_format(type=\"torch\")\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# Define metrics\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(eval_results)\n",
    "\n",
    "\n",
    "model_save_path = \"./ambiguity_detection_model\"\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"\\nModel saved to {model_save_path}\")\n",
    "\n",
    "import json\n",
    "with open(f\"{model_save_path}/label_mapping.json\", 'w') as f:\n",
    "    json.dump(label_mapping, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
